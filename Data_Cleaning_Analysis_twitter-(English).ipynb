{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Author: Dejun Xiang\n",
    "## ID: 349329\n",
    "## Project: Donald Trump analytics\n",
    "## Supervisor: Prof. Richard O. Sinnott\n",
    "## Pre-process tweet (English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the raw data\n",
    "raw_data = pd.read_csv(r\"C:\\Users\\Derek\\Desktop\\twitter\\data\\D-noDulplicate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the important package\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the type of dates from object to datetime64\n",
    "raw_data['dates'] = pd.to_datetime(raw_data['dates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the result\n",
    "raw_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many cells in likes columns is empty\n",
    "raw_data.likes.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling from the raw_data\n",
    "sampleD = sampler(500,raw_data)\n",
    "sampleD.tweet.iloc[55]\n",
    "sampleD.to_csv(r\"C:\\Users\\Derek\\Desktop\\twitter\\sampleD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because there are just a few empty, so we can just drop them\n",
    "raw_data_notnull = raw_data[raw_data['likes'].notnull()].copy()\n",
    "# fix the index to from 0 to the end\n",
    "raw_data_notnull.index = range(len(raw_data_notnull))\n",
    "\n",
    "# convert the data type of number of likes from object to integer\n",
    "for i in range(len(raw_data_notnull)):\n",
    "    s = raw_data_notnull.loc[i,'likes']\n",
    "    raw_data_notnull.loc[i,'likes'] = str_to_int(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_notnull.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the reply phrase (eg. @Donald Trump)\n",
    "rm_reply_symbol(raw_data_notnull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the tweet to single words combining\n",
    "raw_data_notnull_copy = raw_data_notnull.copy()\n",
    "for i in range(len(raw_data_notnull)):\n",
    "    tweet = raw_data_notnull_copy.tweet.loc[i]\n",
    "    clean_t = clean_tweet(tweet)\n",
    "    raw_data_notnull.tweet.loc[i] = clean_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_notnull.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy1 = raw_data_notnull.copy()\n",
    "# Classify tweets into two polary: positive & negtive\n",
    "pol_class = []\n",
    "for i in range(len(raw_data_notnull)):\n",
    "    tweet = data_copy1.loc[i,'tweet']\n",
    "    tb = TextBlob(tweet)\n",
    "    p = tb.sentiment.polarity\n",
    "    if p > 0.1:\n",
    "        result = 1\n",
    "    elif p >= -0.1 and p <= 0.1:\n",
    "        result = 0\n",
    "    else:\n",
    "        result = -1\n",
    "    pol_class.append(result)\n",
    "    if i % 1000 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_notnull['sentiment'] = np.array(pol_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_notnull.groupby('dates').mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the graph of sentiments VS number of tweets post per day\n",
    "%matplotlib notebook\n",
    "d2 = raw_data_notnull.groupby('dates').sentiment.mean()\n",
    "# d2.plot()\n",
    "myplot = d2.plot(kind='line')\n",
    "myplot.set_xlabel('Month in 2018')\n",
    "myplot.set_ylabel('Average twitter posted/day')\n",
    "myplot.set_title('Twitter Sentiment vary through months for English-Users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: convert string number to int (eg. 1.2K --> 1200, 45-->45)\n",
    "Input: numbers(string)\n",
    "Output: int number\n",
    "'''\n",
    "def str_to_int(s):\n",
    "    regexp = re.compile(r'K')\n",
    "    if regexp.search(s):\n",
    "        pattern = r'\\d*\\.?\\d'\n",
    "        m =  re.search(pattern,s)\n",
    "        m1 = m.group()\n",
    "        n = float(m1)\n",
    "        return int(n*1000)\n",
    "    else:\n",
    "        return int(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: remove symbols, stopword;tokenization\n",
    "Input:    raw tweet(string)\n",
    "Output:   cleaned tweet\n",
    "'''\n",
    "def clean_tweet(tweet):\n",
    "    # remove the symbols that are not English\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\",\" \",tweet)\n",
    "    # covert it all to lower case\n",
    "    lower_case = letters_only.lower()\n",
    "    # split them into saperate words\n",
    "    words = lower_case.split()\n",
    "    # get the stopwords and stored in a dictionanry(faster)\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    # remove stop words\n",
    "    words = [w for w in words if not w in stopwords.words(\"english\")]\n",
    "    # re-combine the cleaned and useful words to return\n",
    "    return (\" \".join(words))\n",
    "\n",
    "\n",
    "'''\n",
    "Function: remove reply expression (eg. @DonaldTrump)\n",
    "Input:    raw dataset (dataframe)\n",
    "Output:   cleaned dataset (dataframe)\n",
    "'''\n",
    "def rm_reply_symbol(dataset):\n",
    "    data_copy = dataset.copy()\n",
    "    pattern = re.compile('@\\S*[\\s.,\\/#!$%\\^&\\*;:{}=\\-_`~()]')\n",
    "    length = len(dataset)\n",
    "    for i in range(0,length):\n",
    "        text = data_copy.loc[i,\"tweet\"]\n",
    "        dataset.loc[i,\"tweet\"] = pattern.sub('',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: classify the tweet to positive 1, neutral 0, negtive -1\n",
    "          and return the list of the result\n",
    "Input:    raw dataset (dataframe)\n",
    "Output:   result of classification (list)\n",
    "'''\n",
    "def get_sentiments(dataset):\n",
    "    data_copy = dataset.copy()\n",
    "    # store [classification]\n",
    "    pol_class = []\n",
    "    for i in range(len(dataset)):\n",
    "        tweet = data_copy.loc[i,'tweet']\n",
    "        tb = TextBlob(tweet)\n",
    "        p = tb.sentiment.polarity\n",
    "        if p > 0.1:\n",
    "            result = 1\n",
    "        elif p >= -0.1 and p<= 0.1:\n",
    "            result = 0\n",
    "        else:\n",
    "            result = -1\n",
    "        pol_class.append(result)\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "        \n",
    "    return pol_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: reservior sampler\n",
    "          sampling randomly and uniformly(can be proved by math)\n",
    "          --> find the random index first, then get the rows\n",
    "Input: k (int) --> the number of samples needed\n",
    "       dataset (dataframe)--> the dataframe sampled from\n",
    "Output: sampled dataframe\n",
    "'''\n",
    "def sampler(k,dataset):\n",
    "    index = []\n",
    "    num_rows = len(dataset)\n",
    "    if k > num_rows or k <= 0:\n",
    "        return \"sampling size 'k' is not valid, try other 'k'\"\n",
    "    for i in range(0,num_rows):\n",
    "        if i < k:\n",
    "            index.append(i)\n",
    "        else:\n",
    "            random_index = random.randint(0,i)\n",
    "            if random_index < k:\n",
    "                index[random_index] = i\n",
    "    return dataset.iloc[index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
